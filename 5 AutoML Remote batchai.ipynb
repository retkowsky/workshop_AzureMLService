{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Automated Machine Learning : Remote Execution avec Azure Batch AI\n",
    "\n",
    "In this example we use the scikit-learn's [digit dataset](http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-dataset) to showcase how you can use AutoML for a simple classification problem.\n",
    "\n",
    "Make sure you have executed the [configuration](../configuration.ipynb) before running this notebook.\n",
    "\n",
    "In this notebook you would see\n",
    "1. Create an `Experiment` in an existing `Workspace`.\n",
    "2. Attach an existing Batch AI compute to a workspace.\n",
    "3. Configure AutoML using `AutoMLConfig`.\n",
    "4. Train the model using Batch AI.\n",
    "5. Explore the results.\n",
    "6. Test the best fitted model.\n",
    "\n",
    "In addition this notebook showcases the following features\n",
    "- **Parallel** executions for iterations\n",
    "- **Asynchronous** tracking of progress\n",
    "- **Cancellation** of individual iterations or the entire run\n",
    "- Retrieving models for any iteration or logged metric\n",
    "- Specifying AutoML settings as `**kwargs`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.7 |Anaconda, Inc.| (default, Oct 28 2018, 19:44:12) [MSC v.1915 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Cr√©ation experiment\n",
    "\n",
    "As part of the setup you have already created an Azure ML `Workspace` object. For AutoML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\seretkow\\notebooks\\Labs Azure ML service\\aml_config\\config.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace Name</th>\n",
       "      <td>MLServiceWorkspace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>mlserviceresourcegroup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>westeurope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./sample_projects/automl-remote-batchai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>automl-remote-batchai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          \n",
       "SDK version        1.0.17                                 \n",
       "Workspace Name     MLServiceWorkspace                     \n",
       "Resource Group     mlserviceresourcegroup                 \n",
       "Location           westeurope                             \n",
       "Project Directory  ./sample_projects/automl-remote-batchai\n",
       "Experiment Name    automl-remote-batchai                  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for the run history container in the workspace.\n",
    "experiment_name = 'automl-remote-batchai'\n",
    "project_folder = './sample_projects/automl-remote-batchai'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Workspace Name'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.DataFrame(data = output, index = ['']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Creation cluster Azure Batch AI\n",
    "The cluster is created as Machine Learning Compute and will appear under your workspace.\n",
    "\n",
    "**Note:** The creation of the Batch AI cluster can take over 10 minutes, please be patient.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. Batch AI cluster size) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "batchai_cluster_name = \"automlcl\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "if batchai_cluster_name in cts and cts[batchai_cluster_name].type == 'BatchAI':\n",
    "    found = True\n",
    "    print('Found existing compute target.')\n",
    "    compute_target = cts[batchai_cluster_name]\n",
    "    \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", # for GPU, use \"STANDARD_NC6\"\n",
    "                                                                #vm_priority = 'lowpriority', # optional\n",
    "                                                                max_nodes = 6)\n",
    "\n",
    "    # Create the cluster.\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
    "    \n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "    compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "    \n",
    "     # For a more detailed view of current Batch AI cluster status, use the 'status' property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to the Batch AI cluster\n",
    "conda_run_config.target = compute_target\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "conda_run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\n",
    "\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-sdk[automl]'], conda_packages=['numpy'])\n",
    "conda_run_config.environment.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Get Data File\n",
    "For remote executions you should author a `get_data.py` file containing a `get_data()` function. This file should be in the root directory of the project. You can encapsulate code to read data either from a blob storage or local disk in this file.\n",
    "In this example, the `get_data()` function returns data using scikit-learn's [load_digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(project_folder):\n",
    "    os.makedirs(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sample_projects/automl-remote-batchai/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/get_data.py\n",
    "\n",
    "from sklearn import datasets\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "def get_data():\n",
    "    \n",
    "    digits = datasets.load_digits()\n",
    "    X_train = digits.data\n",
    "    y_train = digits.target\n",
    "\n",
    "    return { \"X\" : X_train, \"y\" : y_train }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 AutoML <a class=\"anchor\" id=\"Instatiate-AutoML-Remote-DSVM\"></a>\n",
    "\n",
    "You can specify `automl_settings` as `**kwargs` as well. Also note that you can use a `get_data()` function for local excutions too.\n",
    "\n",
    "**Note:** When using Batch AI, you can't pass Numpy arrays directly to the fit method.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n",
    "|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n",
    "|**iterations**|Number of iterations. In each iteration AutoML trains a specific pipeline with the data.|\n",
    "|**n_cross_validations**|Number of cross validation splits.|\n",
    "|**max_concurrent_iterations**|Maximum number of iterations that would be executed in parallel. This should be less than the number of cores on the DSVM.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"iterations\": 50,\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"preprocess\": False,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"verbosity\": logging.INFO\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             path = project_folder,\n",
    "                             run_configuration=conda_run_config,\n",
    "                             data_script = project_folder + \"/get_data.py\",\n",
    "                             **automl_settings\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprentissage du mod√®le\n",
    "\n",
    "Call the `submit` method on the experiment object and pass the run configuration. For remote runs the execution is asynchronous, so you will see the iterations get populated as they complete. You can interact with the widgets and models even when the experiment is running to retrieve the best model up to that point. Once you are satisfied with the model, you can cancel a particular iteration or the whole run.\n",
    "In this example, we specify `show_output = False` to suppress console output while the run is in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run = experiment.submit(automl_config, show_output = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Exploration des r√©sultats\n",
    "\n",
    "### 6.5 Chargement\n",
    "In case you need to load a previously executed run, enable the cell below and replace the `run_id` value."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# remote_run = AutoMLRun(experiment = experiment, run_id = 'AutoML_c29563cd-1750-4e73-a663-239657b237a1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Widget for Monitoring Runs\n",
    "\n",
    "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
    "\n",
    "You can click on a pipeline to see run properties and output logs.  Logs are also available on the DSVM under `/tmp/azureml_run/{iterationid}/azureml-logs`\n",
    "\n",
    "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-remote-batchai</td><td>AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a</td><td>automl</td><td>Preparing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourceGroups/mlserviceresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/MLServiceWorkspace/experiments/automl-remote-batchai/runs/AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: automl-remote-batchai,\n",
       "Id: AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a,\n",
       "Type: automl,\n",
       "Status: Preparing)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24679efb2c0b47a292fffbb5ccbbe7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sd‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "SAMPLING %: Percent of the training data to sample.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "********************************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n",
      "         0   RobustScaler KNN                               100.0000    0:00:36       0.9969    0.9969\n",
      "         1   StandardScalerWrapper LightGBM                 100.0000    0:00:55       0.9969    0.9969\n",
      "         2   StandardScalerWrapper LightGBM                 100.0000    0:01:18       0.9979    0.9979\n",
      "         3   SparseNormalizer LightGBM                      100.0000    0:01:40       0.9956    0.9979\n",
      "         4   RobustScaler LightGBM                          100.0000    0:01:55       0.9854    0.9979\n",
      "         5   SparseNormalizer LightGBM                      100.0000    0:02:18       0.9990    0.9990\n",
      "         6   RobustScaler LightGBM                          100.0000    0:02:20       0.9932    0.9990\n",
      "         7   StandardScalerWrapper LightGBM                 100.0000    0:02:18       0.9968    0.9990\n",
      "         8   StandardScalerWrapper LightGBM                 100.0000    0:02:18       0.9956    0.9990\n",
      "         9   StandardScalerWrapper LightGBM                 100.0000    0:02:19       0.9922    0.9990\n",
      "        10   StandardScalerWrapper LightGBM                 100.0000    0:02:19       0.9989    0.9990\n",
      "        11   RobustScaler LogisticRegression                100.0000    0:02:18       0.9956    0.9990\n",
      "        13   MaxAbsScaler LightGBM                          100.0000    0:01:51       0.9987    0.9990\n",
      "        16   StandardScalerWrapper LightGBM                 100.0000    0:00:46       0.9987    0.9990\n",
      "        18   MinMaxScaler LightGBM                          100.0000    0:00:41       0.9982    0.9990\n",
      "        19   StandardScalerWrapper SGD                      100.0000    0:00:36       0.9927    0.9990\n",
      "        20   StandardScalerWrapper LightGBM                 100.0000    0:00:41       0.9985    0.9990\n",
      "        21   MinMaxScaler LightGBM                          100.0000    0:00:39       0.9987    0.9990\n",
      "        15   RobustScaler LightGBM                          100.0000    0:04:18       0.9737    0.9990\n",
      "        14   StandardScalerWrapper LightGBM                 100.0000    0:04:55       0.9983    0.9990\n",
      "        12   SparseNormalizer LightGBM                      100.0000    0:05:53       0.9989    0.9990\n",
      "        22   MaxAbsScaler LightGBM                          100.0000    0:00:29       0.9866    0.9990\n",
      "        23   RobustScaler SVM                               100.0000    0:00:39       0.9994    0.9994\n",
      "        17   StandardScalerWrapper LightGBM                 100.0000    0:04:06       0.9939    0.9994\n",
      "        25   RobustScaler SVM                               100.0000    0:00:34       0.9994    0.9994\n",
      "        24   MaxAbsScaler SVM                               100.0000    0:00:37       0.9997    0.9997\n",
      "        26   MaxAbsScaler LogisticRegression                100.0000    0:00:40       0.9991    0.9997\n",
      "        27   RobustScaler KNN                               100.0000    0:00:35       0.9973    0.9997\n",
      "        28   RobustScaler LogisticRegression                100.0000    0:00:44       0.9978    0.9997\n",
      "        29   RobustScaler SVM                               100.0000    0:00:35       0.9994    0.9997\n",
      "        30   StandardScalerWrapper SVM                      100.0000    0:00:35       0.9996    0.9997\n",
      "        31   StandardScalerWrapper LogisticRegression       100.0000    0:00:34       0.9960    0.9997\n",
      "        32   RobustScaler LogisticRegression                100.0000    0:00:36       0.9988    0.9997\n",
      "        33   StandardScalerWrapper LogisticRegression       100.0000    0:00:35       0.9990    0.9997\n",
      "        34   StandardScalerWrapper LogisticRegression       100.0000    0:00:34       0.9990    0.9997\n",
      "        35   RobustScaler LogisticRegression                100.0000    0:00:39       0.9990    0.9997\n",
      "        36   RobustScaler LogisticRegression                100.0000    0:00:35       0.9990    0.9997\n",
      "        37   MinMaxScaler LogisticRegression                100.0000    0:00:36       0.9972    0.9997\n",
      "        38   MinMaxScaler SVM                               100.0000    0:00:35       0.9996    0.9997\n",
      "        39   MinMaxScaler SVM                               100.0000    0:00:35       0.9997    0.9997\n",
      "        41   StandardScalerWrapper LogisticRegression       100.0000    0:00:34       0.9991    0.9997\n",
      "        40   StandardScalerWrapper SVM                      100.0000    0:00:34       0.9991    0.9997\n",
      "        42   StandardScalerWrapper LogisticRegression       100.0000    0:00:36       0.9976    0.9997\n",
      "        43   StandardScalerWrapper SVM                      100.0000    0:00:34       0.9991    0.9997\n",
      "        45   StandardScalerWrapper SVM                      100.0000    0:00:39       0.9991    0.9997\n",
      "        44   StandardScalerWrapper LogisticRegression       100.0000    0:00:42       0.9984    0.9997\n",
      "        46   StandardScalerWrapper LogisticRegression       100.0000    0:00:40       0.9986    0.9997\n",
      "        48   StandardScalerWrapper LogisticRegression       100.0000    0:00:30       0.9984    0.9997\n",
      "        49    Ensemble                                      100.0000    0:00:59       0.9998    0.9998\n",
      "        47   MinMaxScaler GradientBoosting                  100.0000    0:01:21       0.9991    0.9998\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a',\n",
       " 'target': 'automlcl',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-03-04T11:18:01.456654Z',\n",
       " 'endTimeUtc': '2019-03-04T11:33:54.591497Z',\n",
       " 'properties': {'num_iterations': '50',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'AUC_weighted',\n",
       "  'train_split': '0',\n",
       "  'MaxTimeSeconds': '600',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': '3',\n",
       "  'target': 'automlcl',\n",
       "  'RawAMLSettingsString': \"{'name': 'automl-remote-batchai', 'path': './sample_projects/automl-remote-batchai', 'subscription_id': '70b8f39e-8863-49f7-b6ba-34a80799550c', 'resource_group': 'mlserviceresourcegroup', 'workspace_name': 'MLServiceWorkspace', 'iterations': 50, 'primary_metric': 'AUC_weighted', 'data_script': './sample_projects/automl-remote-batchai/get_data.py', 'compute_target': 'automlcl', 'task_type': 'classification', 'validation_size': 0.0, 'n_cross_validations': 3, 'y_min': None, 'y_max': None, 'num_classes': None, 'preprocess': False, 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 1, 'max_concurrent_iterations': 5, 'iteration_timeout_minutes': 10, 'mem_in_mb': None, 'enforce_time_on_windows': True, 'experiment_timeout_minutes': None, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['XGBoost', 'XGBoostClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': False, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'spark_service': None, 'metrics': None, 'enable_ensembling': True, 'ensemble_iterations': 15, 'enable_tf': True, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'cost_mode': 0, 'metric_operation': 'maximize'}\",\n",
       "  'AMLSettingsJsonString': '{\"name\": \"automl-remote-batchai\", \"path\": \"./sample_projects/automl-remote-batchai\", \"subscription_id\": \"70b8f39e-8863-49f7-b6ba-34a80799550c\", \"resource_group\": \"mlserviceresourcegroup\", \"workspace_name\": \"MLServiceWorkspace\", \"iterations\": 50, \"primary_metric\": \"AUC_weighted\", \"data_script\": \"./sample_projects/automl-remote-batchai/get_data.py\", \"compute_target\": \"automlcl\", \"task_type\": \"classification\", \"validation_size\": 0.0, \"n_cross_validations\": 3, \"y_min\": null, \"y_max\": null, \"num_classes\": null, \"preprocess\": false, \"lag_length\": 0, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 5, \"iteration_timeout_minutes\": 10, \"mem_in_mb\": null, \"enforce_time_on_windows\": true, \"experiment_timeout_minutes\": null, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": [\"XGBoost\", \"XGBoostClassifier\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"model_explainability\": false, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"telemetry_verbosity\": \"INFO\", \"send_telemetry\": true, \"spark_service\": null, \"metrics\": null, \"enable_ensembling\": true, \"ensemble_iterations\": 15, \"enable_tf\": true, \"enable_cache\": true, \"enable_subsampling\": false, \"subsample_seed\": null, \"cost_mode\": 0, \"metric_operation\": \"maximize\"}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'dependencies_versions': '{\"azuremlftk\": \"0.1.19011.2\", \"azureml-widgets\": \"1.0.17\", \"azureml-train\": \"1.0.17\", \"azureml-train-restclients-hyperdrive\": \"1.0.17\", \"azureml-train-core\": \"1.0.17\", \"azureml-train-automl\": \"1.0.17\", \"azureml-telemetry\": \"1.0.17\", \"azureml-sdk\": \"1.0.17\", \"azureml-pipeline\": \"1.0.17\", \"azureml-pipeline-steps\": \"1.0.17\", \"azureml-pipeline-core\": \"1.0.17\", \"azureml-explain-model\": \"1.0.17\", \"azureml-dataprep\": \"1.0.8\", \"azureml-dataprep-native\": \"11.2.1\", \"azureml-core\": \"1.0.17\", \"azureml-contrib-notebook\": \"1.0.17\"}',\n",
       "  'ContentSnapshotId': '0cc9bc42-c187-4a1c-a7fb-c3ab25b20433',\n",
       "  'snapshotId': '0cc9bc42-c187-4a1c-a7fb-c3ab25b20433',\n",
       "  'SetupRunId': 'AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a_setup',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"dataset_classes\": 10, \"dataset_features\": 64, \"dataset_samples\": 1797, \"is_sparse\": false, \"subsampling\": false}'},\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait until the run finishes.\n",
    "remote_run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6.6 Visualisation de tous les runs\n",
    "You can also use SDK methods to fetch all the child runs and see individual metrics that we log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC_macro</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_micro</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_weighted</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_macro</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_micro</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_weighted</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_macro_recall</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_macro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_micro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_weighted</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_macro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_micro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_weighted</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows √ó 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0    1    2    3    4    5    6    7    8  \\\n",
       "AUC_macro                        1.00 1.00 1.00 1.00 0.99 1.00 0.99 1.00 1.00   \n",
       "AUC_micro                        1.00 1.00 1.00 1.00 0.99 1.00 0.99 1.00 1.00   \n",
       "AUC_weighted                     1.00 1.00 1.00 1.00 0.99 1.00 0.99 1.00 1.00   \n",
       "accuracy                         0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "average_precision_score_macro    0.99 0.98 0.99 0.97 0.92 0.99 0.96 0.98 0.97   \n",
       "average_precision_score_micro    0.99 0.98 0.99 0.98 0.92 0.99 0.97 0.98 0.97   \n",
       "average_precision_score_weighted 0.99 0.98 0.99 0.97 0.92 0.99 0.96 0.98 0.97   \n",
       "balanced_accuracy                0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "f1_score_macro                   0.96 0.94 0.95 0.92 0.87 0.96 0.91 0.93 0.91   \n",
       "f1_score_micro                   0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "f1_score_weighted                0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "log_loss                         0.27 0.42 0.47 0.96 1.78 0.18 0.66 0.32 0.58   \n",
       "norm_macro_recall                0.96 0.93 0.94 0.92 0.86 0.96 0.90 0.93 0.91   \n",
       "precision_score_macro            0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "precision_score_micro            0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "precision_score_weighted         0.97 0.94 0.95 0.93 0.88 0.96 0.92 0.94 0.92   \n",
       "recall_score_macro               0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "recall_score_micro               0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "recall_score_weighted            0.96 0.94 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "weighted_accuracy                0.96 0.93 0.95 0.93 0.87 0.96 0.91 0.93 0.92   \n",
       "\n",
       "                                    9 ...    40   41   42   43   44   45   46  \\\n",
       "AUC_macro                        0.99 ...  1.00 1.00 1.00 1.00 1.00 1.00 1.00   \n",
       "AUC_micro                        0.99 ...  1.00 1.00 1.00 1.00 1.00 1.00 1.00   \n",
       "AUC_weighted                     0.99 ...  1.00 1.00 1.00 1.00 1.00 1.00 1.00   \n",
       "accuracy                         0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "average_precision_score_macro    0.96 ...  1.00 0.99 0.99 1.00 0.99 1.00 0.99   \n",
       "average_precision_score_micro    0.96 ...  1.00 0.99 0.99 1.00 0.99 1.00 0.99   \n",
       "average_precision_score_weighted 0.96 ...  1.00 0.99 0.99 1.00 0.99 1.00 0.99   \n",
       "balanced_accuracy                0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "f1_score_macro                   0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "f1_score_micro                   0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "f1_score_weighted                0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "log_loss                         1.03 ...  0.12 0.12 0.20 0.13 0.38 0.13 0.32   \n",
       "norm_macro_recall                0.89 ...  0.98 0.96 0.96 0.98 0.95 0.98 0.96   \n",
       "precision_score_macro            0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "precision_score_micro            0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "precision_score_weighted         0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "recall_score_macro               0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "recall_score_micro               0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "recall_score_weighted            0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "weighted_accuracy                0.90 ...  0.98 0.96 0.96 0.98 0.96 0.98 0.96   \n",
       "\n",
       "                                   47   48   49  \n",
       "AUC_macro                        1.00 1.00 1.00  \n",
       "AUC_micro                        1.00 1.00 1.00  \n",
       "AUC_weighted                     1.00 1.00 1.00  \n",
       "accuracy                         0.97 0.96 0.99  \n",
       "average_precision_score_macro    1.00 0.99 1.00  \n",
       "average_precision_score_micro    1.00 0.99 1.00  \n",
       "average_precision_score_weighted 1.00 0.99 1.00  \n",
       "balanced_accuracy                0.97 0.96 0.99  \n",
       "f1_score_macro                   0.97 0.96 0.99  \n",
       "f1_score_micro                   0.97 0.96 0.99  \n",
       "f1_score_weighted                0.97 0.96 0.99  \n",
       "log_loss                         0.11 0.37 0.17  \n",
       "norm_macro_recall                0.96 0.95 0.99  \n",
       "precision_score_macro            0.97 0.96 0.99  \n",
       "precision_score_micro            0.97 0.96 0.99  \n",
       "precision_score_weighted         0.97 0.96 0.99  \n",
       "recall_score_macro               0.97 0.96 0.99  \n",
       "recall_score_micro               0.97 0.96 0.99  \n",
       "recall_score_weighted            0.97 0.96 0.99  \n",
       "weighted_accuracy                0.97 0.96 0.99  \n",
       "\n",
       "[20 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = list(remote_run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    properties = run.get_properties()\n",
    "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Suppression de runs\n",
    "\n",
    "You can cancel ongoing remote runs using the `cancel` and `cancel_iteration` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel the ongoing experiment and stop scheduling new iterations.\n",
    "# remote_run.cancel()\n",
    "\n",
    "# Cancel iteration 1 and move onto iteration 2.\n",
    "# remote_run.cancel_iteration(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. R√©cup√©ration du meilleur mod√®le \n",
    "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-remote-batchai,\n",
      "Id: AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a_49,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
      "               estimators=[('SVM', Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x000001840613C710>), ('SVCWrapp...666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]))])\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix autre m√©trique\n",
    "Show the run and the model which has the smallest `log_loss` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-remote-batchai,\n",
      "Id: AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a_24,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('MaxAbsScaler', MaxAbsScaler(copy=True)), ('SVCWrapper', SVCWrapper(C=494.1713361323828, cache_size=200, class_weight=None, coef0=0.0,\n",
      "      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "      max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "      tol=0.001, verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "lookup_metric = \"log_loss\"\n",
    "best_run, fitted_model = remote_run.get_output(metric = lookup_metric)\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix it√©ration\n",
    "Show the run and the model from the third iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-remote-batchai,\n",
      "Id: AutoML_64e6c0b1-f396-4754-b3d1-b46c0578ad3a_3,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('SparseNormalizer', <automl.client.core.common.model_wrappers.SparseNormalizer object at 0x00000184060D4710>), ('LightGBMClassifier', <automl.client.core.common.model_wrappers.LightGBMClassifier object at 0x00000184072049B0>)])\n"
     ]
    }
   ],
   "source": [
    "iteration = 3\n",
    "third_run, third_model = remote_run.get_output(iteration=iteration)\n",
    "print(third_run)\n",
    "print(third_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test du mod√®le <a class=\"anchor\" id=\"Testing-the-Fitted-Model-Remote-DSVM\"></a>\n",
    "\n",
    "#### Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X_test = digits.data[:10, :]\n",
    "y_test = digits.target[:10]\n",
    "images = digits.images[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly select digits and test.\n",
    "for index in np.random.choice(len(y_test), 2, replace = False):\n",
    "    print(index)\n",
    "    predicted = fitted_model.predict(X_test[index:index + 1])[0]\n",
    "    label = y_test[index]\n",
    "    title = \"Label value = %d  Predicted value = %d \" % (label, predicted)\n",
    "    fig = plt.figure(1, figsize=(3,3))\n",
    "    ax1 = fig.add_axes((0,0,.8,.8))\n",
    "    ax1.set_title(title)\n",
    "    plt.imshow(images[index], cmap = plt.cm.gray_r, interpolation = 'nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "savitam"
   }
  ],
  "kernelspec": {
   "display_name": "Python [conda env:AzureML]",
   "language": "python",
   "name": "conda-env-AzureML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
