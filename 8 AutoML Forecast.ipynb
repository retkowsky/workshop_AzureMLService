{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "_**Orange Juice Sales Forecasting**_\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "\n",
    "> https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-automated-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this example, we use AutoML to find and tune a time-series forecasting model.\n",
    "\n",
    "Make sure you have executed the [configuration notebook](../../../configuration.ipynb) before running this notebook.\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create an Experiment in an existing Workspace\n",
    "2. Instantiate an AutoMLConfig \n",
    "3. Find and train a forecasting model using local compute\n",
    "4. Evaluate the performance of the model\n",
    "\n",
    "The examples in the follow code samples use the [University of Chicago's Dominick's Finer Foods dataset](https://research.chicagobooth.edu/kilts/marketing-databases/dominicks) to forecast orange juice sales. Dominick's was a grocery chain in the Chicago metropolitan area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As part of the setup you have already created a <b>Workspace</b>. To run AutoML, you also need to create an <b>Experiment</b>. An Experiment is a named object in a Workspace which represents a predictive task, the output of which is a trained model and a set of evaluation metrics for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "# Squash warning messages for cleaner output in the notebook\n",
    "warnings.showwarning = lambda *args, **kwargs: None\n",
    "\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise Ã  jour package Azuremlftk pour option FORECAST AutoML\n",
    "#!pip install azuremlftk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Azure ML service : 1.0.17\n"
     ]
    }
   ],
   "source": [
    "# Version Azure ML service\n",
    "import azureml.core\n",
    "print(\"Version Azure ML service :\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.7 |Anaconda, Inc.| (default, Oct 28 2018, 19:44:12) [MSC v.1915 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version Python\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\seretkow\\notebooks\\Labs Azure ML service\\aml_config\\config.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>MLServiceWorkspace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>mlserviceresourcegroup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>westeurope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./sample_projects/automl-local-ojsalesforecasting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run History Name</th>\n",
       "      <td>automl-ojsalesforecasting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    \n",
       "SDK version        1.0.17                                           \n",
       "Workspace          MLServiceWorkspace                               \n",
       "Resource Group     mlserviceresourcegroup                           \n",
       "Location           westeurope                                       \n",
       "Project Directory  ./sample_projects/automl-local-ojsalesforecasting\n",
       "Run History Name   automl-ojsalesforecasting                        "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for the run history container in the workspace\n",
    "experiment_name = 'automl-ojsalesforecasting'\n",
    "# project folder\n",
    "project_folder = './sample_projects/automl-local-ojsalesforecasting'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Run History Name'] = experiment_name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "You are now ready to load the historical orange juice sales data. We will load the CSV file into a plain pandas DataFrame; the time column in the CSV is called _WeekStarting_, so it will be specially parsed into the datetime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekStarting</th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>logQuantity</th>\n",
       "      <th>Advert</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age60</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>Hincome150</th>\n",
       "      <th>Large HH</th>\n",
       "      <th>Minorities</th>\n",
       "      <th>WorkingWoman</th>\n",
       "      <th>SSTRDIST</th>\n",
       "      <th>SSTRVOL</th>\n",
       "      <th>CPDIST5</th>\n",
       "      <th>CPWVOL5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>2</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>10560</td>\n",
       "      <td>9.26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>2</td>\n",
       "      <td>minute.maid</td>\n",
       "      <td>4480</td>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>2</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>8256</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>5</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>1792</td>\n",
       "      <td>7.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10.92</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>5</td>\n",
       "      <td>minute.maid</td>\n",
       "      <td>4224</td>\n",
       "      <td>8.35</td>\n",
       "      <td>0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10.92</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WeekStarting  Store        Brand  Quantity  logQuantity  Advert  Price  \\\n",
       "0 1990-06-14    2      dominicks    10560    9.26          1      1.59     \n",
       "1 1990-06-14    2      minute.maid  4480     8.41          0      3.17     \n",
       "2 1990-06-14    2      tropicana    8256     9.02          0      3.87     \n",
       "3 1990-06-14    5      dominicks    1792     7.49          1      1.59     \n",
       "4 1990-06-14    5      minute.maid  4224     8.35          0      2.99     \n",
       "\n",
       "   Age60  COLLEGE  INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n",
       "0 0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
       "1 0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
       "2 0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
       "3 0.12   0.32     10.92   0.54        0.10      0.05        0.41            \n",
       "4 0.12   0.32     10.92   0.54        0.10      0.05        0.41            \n",
       "\n",
       "   SSTRDIST  SSTRVOL  CPDIST5  CPWVOL5  \n",
       "0 2.11      1.14     1.93     0.38      \n",
       "1 2.11      1.14     1.93     0.38      \n",
       "2 2.11      1.14     1.93     0.38      \n",
       "3 3.80      0.68     1.60     0.74      \n",
       "4 3.80      0.68     1.60     0.74      "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_column_name = 'WeekStarting'\n",
    "data = pd.read_csv(\"dominicks_OJ.csv\", parse_dates=[time_column_name])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the DataFrame holds a quantity of weekly sales for an OJ brand at a single store. The data also includes the sales price, a flag indicating if the OJ brand was advertised in the store that week, and some customer demographic information based on the store location. For historical reasons, the data also include the logarithm of the sales quantity. The Dominick's grocery data is commonly used to illustrate econometric modeling techniques where logarithms of quantities are generally preferred.    \n",
    "\n",
    "The task is now to build a time-series model for the _Quantity_ column. It is important to note that this dataset is comprised of many individual time-series - one for each unique combination of _Store_ and _Brand_. To distinguish the individual time-series, we thus define the **grain** - the columns whose values determine the boundaries between time-series: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains 249 individual time-series.\n"
     ]
    }
   ],
   "source": [
    "grain_column_names = ['Store', 'Brand']\n",
    "nseries = data.groupby(grain_column_names).ngroups\n",
    "print('Data contains {0} individual time-series.'.format(nseries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "For the purposes of demonstration and later forecast evaluation, we now split the data into a training and a testing set. The test set will contain the final 20 weeks of observed sales for each time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest_periods = 20\n",
    "\n",
    "def split_last_n_by_grain(df, n):\n",
    "    \"\"\"\n",
    "    Group df by grain and split on last n rows for each group\n",
    "    \"\"\"\n",
    "    df_grouped = (df.sort_values(time_column_name) # Sort by ascending time\n",
    "                  .groupby(grain_column_names, group_keys=False))\n",
    "    df_head = df_grouped.apply(lambda dfg: dfg.iloc[:-n])\n",
    "    df_tail = df_grouped.apply(lambda dfg: dfg.iloc[-n:])\n",
    "    return df_head, df_tail\n",
    "\n",
    "X_train, X_test = split_last_n_by_grain(data, ntest_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      WeekStarting  Store      Brand  Quantity  logQuantity  Advert  Price  \\\n",
      "0     1990-06-14    2      dominicks  10560    9.26          1      1.59     \n",
      "1305  1990-07-26    2      dominicks  8000     8.99          0      2.69     \n",
      "1533  1990-08-02    2      dominicks  6848     8.83          1      2.09     \n",
      "1758  1990-08-09    2      dominicks  2880     7.97          0      2.09     \n",
      "2217  1990-08-23    2      dominicks  1600     7.38          0      2.09     \n",
      "2454  1990-08-30    2      dominicks  25344    10.14         1      1.89     \n",
      "2694  1990-09-06    2      dominicks  10752    9.28          0      1.89     \n",
      "2931  1990-09-13    2      dominicks  6656     8.80          0      1.89     \n",
      "3168  1990-09-20    2      dominicks  6592     8.79          0      1.79     \n",
      "3879  1990-10-11    2      dominicks  1728     7.45          0      2.69     \n",
      "4119  1990-10-18    2      dominicks  33792    10.43         1      1.24     \n",
      "4362  1990-10-25    2      dominicks  1920     7.56          0      1.59     \n",
      "4602  1990-11-01    2      dominicks  8960     9.10          1      1.59     \n",
      "4839  1990-11-08    2      dominicks  11392    9.34          0      1.29     \n",
      "5076  1990-11-15    2      dominicks  28416    10.25         0      0.99     \n",
      "5319  1990-11-22    2      dominicks  17152    9.75          1      1.59     \n",
      "5565  1990-11-29    2      dominicks  26560    10.19         1      2.49     \n",
      "5808  1990-12-06    2      dominicks  6336     8.75          0      2.69     \n",
      "6051  1990-12-13    2      dominicks  26368    10.18         1      1.39     \n",
      "6294  1990-12-20    2      dominicks  896      6.80          0      2.69     \n",
      "6540  1990-12-27    2      dominicks  1472     7.29          0      2.69     \n",
      "6768  1991-01-03    2      dominicks  1344     7.20          0      2.69     \n",
      "7005  1991-01-10    2      dominicks  111680   11.62         1      0.99     \n",
      "7245  1991-01-17    2      dominicks  1856     7.53          0      2.69     \n",
      "7491  1991-01-24    2      dominicks  5568     8.62          0      2.69     \n",
      "7734  1991-01-31    2      dominicks  32064    10.38         1      1.49     \n",
      "7980  1991-02-07    2      dominicks  4352     8.38          0      1.49     \n",
      "8229  1991-02-14    2      dominicks  704      6.56          0      2.69     \n",
      "8472  1991-02-21    2      dominicks  13760    9.53          0      2.69     \n",
      "8715  1991-02-28    2      dominicks  43328    10.68         1      1.09     \n",
      "...          ...   ..            ...    ...      ...        ..       ...     \n",
      "17045 1991-10-24    137    tropicana  16064    9.68          0      3.07     \n",
      "17291 1991-10-31    137    tropicana  16512    9.71          0      3.07     \n",
      "17534 1991-11-07    137    tropicana  22528    10.02         0      3.11     \n",
      "17780 1991-11-14    137    tropicana  20032    9.91          0      3.19     \n",
      "18017 1991-11-21    137    tropicana  123136   11.72         1      1.99     \n",
      "18263 1991-11-28    137    tropicana  24768    10.12         0      2.84     \n",
      "18506 1991-12-05    137    tropicana  17088    9.75          0      3.19     \n",
      "18743 1991-12-12    137    tropicana  15296    9.64          0      3.19     \n",
      "18962 1991-12-19    137    tropicana  21696    9.98          0      2.83     \n",
      "19121 1991-12-26    137    tropicana  47744    10.77         0      2.39     \n",
      "19511 1992-01-02    137    tropicana  49792    10.82         0      2.34     \n",
      "19754 1992-01-09    137    tropicana  50368    10.83         0      2.29     \n",
      "20003 1992-01-16    137    tropicana  35520    10.48         0      2.37     \n",
      "20252 1992-01-23    137    tropicana  14848    9.61          0      3.18     \n",
      "20498 1992-01-30    137    tropicana  17408    9.76          0      3.19     \n",
      "20744 1992-02-06    137    tropicana  18752    9.84          0      3.19     \n",
      "20993 1992-02-13    137    tropicana  99968    11.51         1      1.99     \n",
      "21227 1992-02-20    137    tropicana  15872    9.67          0      3.19     \n",
      "21473 1992-02-27    137    tropicana  130624   11.78         1      1.99     \n",
      "21719 1992-03-05    137    tropicana  108480   11.59         0      1.79     \n",
      "21968 1992-03-12    137    tropicana  103936   11.55         0      1.79     \n",
      "22217 1992-03-19    137    tropicana  40256    10.60         0      1.95     \n",
      "22463 1992-03-26    137    tropicana  35392    10.47         0      2.76     \n",
      "22712 1992-04-02    137    tropicana  100864   11.52         1      2.50     \n",
      "22958 1992-04-09    137    tropicana  69056    11.14         0      2.59     \n",
      "23204 1992-04-16    137    tropicana  23680    10.07         0      3.19     \n",
      "23453 1992-04-23    137    tropicana  25728    10.16         0      2.74     \n",
      "23702 1992-04-30    137    tropicana  80384    11.29         1      2.39     \n",
      "23945 1992-05-07    137    tropicana  30464    10.32         0      3.19     \n",
      "24191 1992-05-14    137    tropicana  27904    10.24         0      3.19     \n",
      "\n",
      "       Age60  COLLEGE  INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n",
      "0     0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "1305  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "1533  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "1758  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "2217  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "2454  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "2694  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "2931  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "3168  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "3879  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "4119  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "4362  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "4602  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "4839  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "5076  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "5319  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "5565  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "5808  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "6051  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "6294  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "6540  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "6768  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "7005  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "7245  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "7491  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "7734  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "7980  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "8229  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "8472  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "8715  0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n",
      "...    ...    ...       ...    ...         ...       ...         ...            \n",
      "17045 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "17291 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "17534 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "17780 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "18017 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "18263 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "18506 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "18743 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "18962 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "19121 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "19511 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "19754 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "20003 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "20252 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "20498 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "20744 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "20993 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "21227 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "21473 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "21719 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "21968 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "22217 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "22463 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "22712 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "22958 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "23204 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "23453 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "23702 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "23945 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "24191 0.21   0.53     10.97   0.86        0.09      0.11        0.33            \n",
      "\n",
      "       SSTRDIST  SSTRVOL  CPDIST5  CPWVOL5  \n",
      "0     2.11      1.14     1.93     0.38      \n",
      "1305  2.11      1.14     1.93     0.38      \n",
      "1533  2.11      1.14     1.93     0.38      \n",
      "1758  2.11      1.14     1.93     0.38      \n",
      "2217  2.11      1.14     1.93     0.38      \n",
      "2454  2.11      1.14     1.93     0.38      \n",
      "2694  2.11      1.14     1.93     0.38      \n",
      "2931  2.11      1.14     1.93     0.38      \n",
      "3168  2.11      1.14     1.93     0.38      \n",
      "3879  2.11      1.14     1.93     0.38      \n",
      "4119  2.11      1.14     1.93     0.38      \n",
      "4362  2.11      1.14     1.93     0.38      \n",
      "4602  2.11      1.14     1.93     0.38      \n",
      "4839  2.11      1.14     1.93     0.38      \n",
      "5076  2.11      1.14     1.93     0.38      \n",
      "5319  2.11      1.14     1.93     0.38      \n",
      "5565  2.11      1.14     1.93     0.38      \n",
      "5808  2.11      1.14     1.93     0.38      \n",
      "6051  2.11      1.14     1.93     0.38      \n",
      "6294  2.11      1.14     1.93     0.38      \n",
      "6540  2.11      1.14     1.93     0.38      \n",
      "6768  2.11      1.14     1.93     0.38      \n",
      "7005  2.11      1.14     1.93     0.38      \n",
      "7245  2.11      1.14     1.93     0.38      \n",
      "7491  2.11      1.14     1.93     0.38      \n",
      "7734  2.11      1.14     1.93     0.38      \n",
      "7980  2.11      1.14     1.93     0.38      \n",
      "8229  2.11      1.14     1.93     0.38      \n",
      "8472  2.11      1.14     1.93     0.38      \n",
      "8715  2.11      1.14     1.93     0.38      \n",
      "...    ...       ...      ...      ...      \n",
      "17045 6.03      0.71     0.77     0.33      \n",
      "17291 6.03      0.71     0.77     0.33      \n",
      "17534 6.03      0.71     0.77     0.33      \n",
      "17780 6.03      0.71     0.77     0.33      \n",
      "18017 6.03      0.71     0.77     0.33      \n",
      "18263 6.03      0.71     0.77     0.33      \n",
      "18506 6.03      0.71     0.77     0.33      \n",
      "18743 6.03      0.71     0.77     0.33      \n",
      "18962 6.03      0.71     0.77     0.33      \n",
      "19121 6.03      0.71     0.77     0.33      \n",
      "19511 6.03      0.71     0.77     0.33      \n",
      "19754 6.03      0.71     0.77     0.33      \n",
      "20003 6.03      0.71     0.77     0.33      \n",
      "20252 6.03      0.71     0.77     0.33      \n",
      "20498 6.03      0.71     0.77     0.33      \n",
      "20744 6.03      0.71     0.77     0.33      \n",
      "20993 6.03      0.71     0.77     0.33      \n",
      "21227 6.03      0.71     0.77     0.33      \n",
      "21473 6.03      0.71     0.77     0.33      \n",
      "21719 6.03      0.71     0.77     0.33      \n",
      "21968 6.03      0.71     0.77     0.33      \n",
      "22217 6.03      0.71     0.77     0.33      \n",
      "22463 6.03      0.71     0.77     0.33      \n",
      "22712 6.03      0.71     0.77     0.33      \n",
      "22958 6.03      0.71     0.77     0.33      \n",
      "23204 6.03      0.71     0.77     0.33      \n",
      "23453 6.03      0.71     0.77     0.33      \n",
      "23702 6.03      0.71     0.77     0.33      \n",
      "23945 6.03      0.71     0.77     0.33      \n",
      "24191 6.03      0.71     0.77     0.33      \n",
      "\n",
      "[23967 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "For forecasting tasks, AutoML uses pre-processing and estimation steps that are specific to time-series. AutoML will undertake the following pre-processing steps:\n",
    "* Detect time-series sample frequency (e.g. hourly, daily, weekly) and create new records for absent time points to make the series regular. A regular time series has a well-defined frequency and has a value at every sample point in a contiguous time span \n",
    "* Impute missing values in the target (via forward-fill) and feature columns (using median column values) \n",
    "* Create grain-based features to enable fixed effects across different series\n",
    "* Create time-based features to assist in learning seasonal patterns\n",
    "* Encode categorical variables to numeric quantities\n",
    "\n",
    "AutoML will currently train a single, regression-type model across **all** time-series in a given training set. This allows the model to generalize across related series.\n",
    "\n",
    "You are almost ready to start an AutoML training job. We will first need to create a validation set from the existing training set (i.e. for hyper-parameter tuning): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvalidation_periods = 20\n",
    "X_train, X_validate = split_last_n_by_grain(X_train, nvalidation_periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to separate the target column from the rest of the DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = 'Quantity'\n",
    "y_train = X_train.pop(target_column_name).values\n",
    "y_validate = X_validate.pop(target_column_name).values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10560  8000  6848 ... 15296 21696 47744]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "The AutoMLConfig object defines the settings and data for an AutoML training job. Here, we set necessary inputs like the task type, the number of AutoML iterations to try, and the training and validation data. \n",
    "\n",
    "For forecasting tasks, there are some additional parameters that can be set: the name of the column holding the date/time and the grain column names. A time column is required for forecasting, while the grain is optional. If a grain is not given, the forecaster assumes that the whole dataset is a single time-series. We also pass a list of columns to drop prior to modeling. The _logQuantity_ column is completely correlated with the target quantity, so it must be removed to prevent a target leak. \n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|forecasting|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>\n",
    "|**iterations**|Number of iterations. In each iteration, Auto ML trains a specific pipeline on the given data|\n",
    "|**X**|Training matrix of features, shape = [n_training_samples, n_features]|\n",
    "|**y**|Target values, shape = [n_training_samples, ]|\n",
    "|**X_valid**|Validation matrix of features, shape = [n_validation_samples, n_features]|\n",
    "|**y_valid**|Target values for validation, shape = [n_validation_samples, ]\n",
    "|**enable_ensembling**|Allow AutoML to create ensembles of the best performing models\n",
    "|**debug_log**|Log file path for writing debugging information\n",
    "|**path**|Relative path to the project folder.  AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    'time_column_name': time_column_name,\n",
    "    'grain_column_names': grain_column_names,\n",
    "    'drop_column_names': ['logQuantity']\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task='forecasting',\n",
    "                             debug_log='automl_oj_sales_errors.log',\n",
    "                             primary_metric='normalized_root_mean_squared_error',\n",
    "                             iterations=10,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             X_valid=X_validate,\n",
    "                             y_valid=y_validate,\n",
    "                             enable_ensembling=False,\n",
    "                             path=project_folder,\n",
    "                             verbosity=logging.INFO,\n",
    "                            **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now submit a new training run. For local runs, the execution is synchronous. Depending on the data and number of iterations this operation may take several minutes.\n",
    "Information from each iteration will be printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_ee04ee7e-9c6b-4edd-9676-df5bdae3e169\n",
      "********************************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "SAMPLING %: Percent of the training data to sample.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "********************************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper ElasticNet               100.0000    0:00:03       0.0300    0.0300\n",
      "         1   TruncatedSVDWrapper ElasticNet                 100.0000    0:01:17       0.0310    0.0300\n",
      "         2   RobustScaler ElasticNet                        100.0000    0:00:04       0.0299    0.0299\n",
      "         3   StandardScalerWrapper ElasticNet               100.0000    0:00:05       0.0327    0.0299\n",
      "         4   StandardScalerWrapper ElasticNet               100.0000    0:00:03       0.0298    0.0298\n",
      "         5   StandardScalerWrapper RandomForest             100.0000    0:00:03       0.0298    0.0298\n",
      "         6   StandardScalerWrapper LightGBM                 100.0000    0:00:07       0.0293    0.0293\n",
      "         7   StandardScalerWrapper ExtremeRandomTrees       100.0000    0:00:03       0.0295    0.0293\n",
      "         8   StandardScalerWrapper LightGBM                 100.0000    0:00:03       0.0289    0.0289\n",
      "         9   RobustScaler ElasticNet                        100.0000    0:00:02       0.0336    0.0289\n"
     ]
    }
   ],
   "source": [
    "local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-ojsalesforecasting</td><td>AutoML_ee04ee7e-9c6b-4edd-9676-df5bdae3e169</td><td>automl</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourceGroups/mlserviceresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/MLServiceWorkspace/experiments/automl-ojsalesforecasting/runs/AutoML_ee04ee7e-9c6b-4edd-9676-df5bdae3e169\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: automl-ojsalesforecasting,\n",
       "Id: AutoML_ee04ee7e-9c6b-4edd-9676-df5bdae3e169,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model\n",
    "Each run within an Experiment stores serialized (i.e. pickled) pipelines from the AutoML iterations. We can now retrieve the pipeline with the best performance on the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('timeseriestransformer', TimeSeriesTransformer(logger=None)),\n",
       " ('standardscalerwrapper',\n",
       "  <automl.client.core.common.model_wrappers.StandardScalerWrapper at 0x2141b1ab8d0>),\n",
       " ('lightgbmregressor',\n",
       "  <automl.client.core.common.model_wrappers.LightGBMRegressor at 0x2141b1ab278>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run, fitted_pipeline = local_run.get_output()\n",
    "fitted_pipeline.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions from the Best Fitted Model\n",
    "Now that we have retrieved the best pipeline/model, it can be used to make predictions on test data. First, we remove the target values from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test.pop(target_column_name).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekStarting</th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>logQuantity</th>\n",
       "      <th>Advert</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age60</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>Hincome150</th>\n",
       "      <th>Large HH</th>\n",
       "      <th>Minorities</th>\n",
       "      <th>WorkingWoman</th>\n",
       "      <th>SSTRDIST</th>\n",
       "      <th>SSTRVOL</th>\n",
       "      <th>CPDIST5</th>\n",
       "      <th>CPWVOL5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24192</th>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>2</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>9.18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24441</th>\n",
       "      <td>1992-05-28</td>\n",
       "      <td>2</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>10.73</td>\n",
       "      <td>0</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24675</th>\n",
       "      <td>1992-06-04</td>\n",
       "      <td>2</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24909</th>\n",
       "      <td>1992-06-11</td>\n",
       "      <td>2</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>8.79</td>\n",
       "      <td>0</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25152</th>\n",
       "      <td>1992-06-18</td>\n",
       "      <td>2</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WeekStarting  Store      Brand  logQuantity  Advert  Price  Age60  \\\n",
       "24192 1992-05-21    2      dominicks 9.18          0      1.69   0.23     \n",
       "24441 1992-05-28    2      dominicks 10.73         0      1.69   0.23     \n",
       "24675 1992-06-04    2      dominicks 9.95          0      1.74   0.23     \n",
       "24909 1992-06-11    2      dominicks 8.79          0      2.09   0.23     \n",
       "25152 1992-06-18    2      dominicks 8.52          0      2.05   0.23     \n",
       "\n",
       "       COLLEGE  INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n",
       "24192 0.25     10.55   0.46        0.10      0.11        0.30            \n",
       "24441 0.25     10.55   0.46        0.10      0.11        0.30            \n",
       "24675 0.25     10.55   0.46        0.10      0.11        0.30            \n",
       "24909 0.25     10.55   0.46        0.10      0.11        0.30            \n",
       "25152 0.25     10.55   0.46        0.10      0.11        0.30            \n",
       "\n",
       "       SSTRDIST  SSTRVOL  CPDIST5  CPWVOL5  \n",
       "24192 2.11      1.14     1.93     0.38      \n",
       "24441 2.11      1.14     1.93     0.38      \n",
       "24675 2.11      1.14     1.93     0.38      \n",
       "24909 2.11      1.14     1.93     0.38      \n",
       "25152 2.11      1.14     1.93     0.38      "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce predictions on the test set, we need to know the feature values at all dates in the test set. This requirement is somewhat reasonable for the OJ sales data since the features mainly consist of price, which is usually set in advance, and customer demographics which are approximately constant for each store over the 20 week forecast horizon in the testing data. \n",
    "\n",
    "The target predictions can be retrieved by calling the `predict` method on the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fitted_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7148.6533585   6395.1264224   7476.54370344 ... 14717.9139984\n",
      " 32862.70849477 16173.54739328]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate evaluation metrics for the prediction\n",
    "To evaluate the accuracy of the forecast, we'll compare against the actual sales quantities for some select metrics, included the mean absolute percentage error (MAPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Data] \n",
      "Root Mean squared error: 17082.02\n",
      "mean_absolute_error score: 9384.22\n",
      "MAPE: 81.14\n"
     ]
    }
   ],
   "source": [
    "def MAPE(actual, pred):\n",
    "    \"\"\"\n",
    "    Calculate mean absolute percentage error.\n",
    "    Remove NA and values where actual is close to zero\n",
    "    \"\"\"\n",
    "    not_na = ~(np.isnan(actual) | np.isnan(pred))\n",
    "    not_zero = ~np.isclose(actual, 0.0)\n",
    "    actual_safe = actual[not_na & not_zero]\n",
    "    pred_safe = pred[not_na & not_zero]\n",
    "    APE = 100*np.abs((actual_safe - pred_safe)/actual_safe)\n",
    "    return np.mean(APE)\n",
    "\n",
    "print(\"[Test Data] \\nRoot Mean squared error: %.2f\" % np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('mean_absolute_error score: %.2f' % mean_absolute_error(y_test, y_pred))\n",
    "print('MAPE: %.2f' % MAPE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "erwright"
   }
  ],
  "kernelspec": {
   "display_name": "Python [conda env:AzureML]",
   "language": "python",
   "name": "conda-env-AzureML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
