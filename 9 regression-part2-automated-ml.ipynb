{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Tutorial #2: Train a regression model with automated machine learning\n\nThis tutorial is **part two of a two-part tutorial series**. In the previous tutorial, you [prepared the NYC taxi data for regression modeling](regression-part1-data-prep.ipynb).\n\nNow, you're ready to start building your model with Azure Machine Learning service. In this part of the tutorial, you will use the prepared data and automatically generate a regression model to predict taxi fare prices. Using the automated ML capabilities of the service, you define your machine learning goals and constraints, launch the automated machine learning process and then allow the algorithm selection and hyperparameter-tuning to happen for you. The automated ML technique iterates over many combinations of algorithms and hyperparameters until it finds the best model based on your criterion.\n\nIn this tutorial, you learn how to:\n\n> * Setup a Python environment and import the SDK packages\n> * Configure an Azure Machine Learning service workspace\n> * Auto-train a regression model \n> * Run the model locally with custom parameters\n> * Explore the results\n> * Register the best model\n\nIf you don’t have an Azure subscription, create a [free account](https://aka.ms/AMLfree) before you begin. \n\n> Code in this article was tested with Azure Machine Learning SDK version 1.0.0\n\n\n## Prerequisites\n\n> * [Run the data preparation tutorial](regression-part1-data-prep.ipynb)\n\n> * Automated machine learning configured environment e.g. Azure notebooks, Local Python environment or Data Science Virtual Machine. [Setup](https://docs.microsoft.com/azure/machine-learning/service/samples-notebooks) automated machine learning."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Import packages\nImport Python packages you need in this tutorial."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\nimport pandas as pd\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl.run import AutoMLRun\nimport time\nimport logging",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Configure workspace\n\nCreate a workspace object from the existing workspace. A `Workspace` is a class that accepts your Azure subscription and resource information, and creates a cloud resource to monitor and track your model runs. `Workspace.from_config()` reads the file **aml_config/config.json** and loads the details into an object named `ws`.  `ws` is used throughout the rest of the code in this tutorial.\n\nOnce you have a workspace object, specify a name for the experiment and create and register a local directory with the workspace. The history of all runs is recorded under the specified experiment."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()\n# choose a name for the run history container in the workspace\nexperiment_name = 'automated-ml-regression'\n# project folder\nproject_folder = './automated-ml-regression'\n\nimport os\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\npd.set_option('display.max_colwidth', -1)\npd.DataFrame(data=output, index=['']).T",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/aml_config/config.json\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Location</th>\n      <td>westeurope</td>\n    </tr>\n    <tr>\n      <th>Project Directory</th>\n      <td>./automated-ml-regression</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>resgrpAMLS</td>\n    </tr>\n    <tr>\n      <th>SDK version</th>\n      <td>1.0.2</td>\n    </tr>\n    <tr>\n      <th>Subscription ID</th>\n      <td>70b8f39e-8863-49f7-b6ba-34a80799550c</td>\n    </tr>\n    <tr>\n      <th>Workspace</th>\n      <td>AMLSworkspace</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                       \nLocation           westeurope                          \nProject Directory  ./automated-ml-regression           \nResource Group     resgrpAMLS                          \nSDK version        1.0.2                               \nSubscription ID    70b8f39e-8863-49f7-b6ba-34a80799550c\nWorkspace          AMLSworkspace                       "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Explore data\n\nUtilize the data flow object created in the previous tutorial. Open and execute the data flow and review the results."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.dataprep as dprep\npackage_saved = dprep.Package.open(\"dflows\")\ndflow_prepared = package_saved.dataflows[0]\ndflow_prepared.get_profile()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Min</th>\n      <th>Max</th>\n      <th>Count</th>\n      <th>Missing Count</th>\n      <th>Not Missing Count</th>\n      <th>Percent missing</th>\n      <th>Error Count</th>\n      <th>Empty count</th>\n      <th>0.1% Quantile</th>\n      <th>1% Quantile</th>\n      <th>5% Quantile</th>\n      <th>25% Quantile</th>\n      <th>50% Quantile</th>\n      <th>75% Quantile</th>\n      <th>95% Quantile</th>\n      <th>99% Quantile</th>\n      <th>99.9% Quantile</th>\n      <th>Mean</th>\n      <th>Standard Deviation</th>\n      <th>Variance</th>\n      <th>Skewness</th>\n      <th>Kurtosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>vendor</th>\n      <td>FieldType.STRING</td>\n      <td>1</td>\n      <td>VTS</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>pickup_weekday</th>\n      <td>FieldType.STRING</td>\n      <td>Friday</td>\n      <td>Wednesday</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>pickup_hour</th>\n      <td>FieldType.DECIMAL</td>\n      <td>0</td>\n      <td>23</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3.57523</td>\n      <td>3</td>\n      <td>9.91106</td>\n      <td>15.9327</td>\n      <td>19</td>\n      <td>22.0225</td>\n      <td>23</td>\n      <td>23</td>\n      <td>14.2326</td>\n      <td>6.34926</td>\n      <td>40.3131</td>\n      <td>-0.693335</td>\n      <td>-0.459336</td>\n    </tr>\n    <tr>\n      <th>pickup_minute</th>\n      <td>FieldType.DECIMAL</td>\n      <td>0</td>\n      <td>59</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5.32313</td>\n      <td>4.92308</td>\n      <td>14.2214</td>\n      <td>29.5244</td>\n      <td>44.6436</td>\n      <td>56.3767</td>\n      <td>58.9798</td>\n      <td>59</td>\n      <td>29.4635</td>\n      <td>17.4396</td>\n      <td>304.14</td>\n      <td>0.00440324</td>\n      <td>-1.20458</td>\n    </tr>\n    <tr>\n      <th>pickup_second</th>\n      <td>FieldType.DECIMAL</td>\n      <td>0</td>\n      <td>59</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4.99286</td>\n      <td>4.91954</td>\n      <td>14.6121</td>\n      <td>29.9239</td>\n      <td>44.5221</td>\n      <td>56.6792</td>\n      <td>59</td>\n      <td>59</td>\n      <td>29.6225</td>\n      <td>17.3868</td>\n      <td>302.302</td>\n      <td>-0.0227466</td>\n      <td>-1.19409</td>\n    </tr>\n    <tr>\n      <th>dropoff_weekday</th>\n      <td>FieldType.STRING</td>\n      <td>Friday</td>\n      <td>Wednesday</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>dropoff_hour</th>\n      <td>FieldType.DECIMAL</td>\n      <td>0</td>\n      <td>23</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3.23217</td>\n      <td>2.93333</td>\n      <td>9.92334</td>\n      <td>15.9135</td>\n      <td>19</td>\n      <td>22.2739</td>\n      <td>23</td>\n      <td>23</td>\n      <td>14.1815</td>\n      <td>6.45578</td>\n      <td>41.677</td>\n      <td>-0.691001</td>\n      <td>-0.500215</td>\n    </tr>\n    <tr>\n      <th>dropoff_minute</th>\n      <td>FieldType.DECIMAL</td>\n      <td>0</td>\n      <td>59</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5.1064</td>\n      <td>5</td>\n      <td>14.2051</td>\n      <td>29.079</td>\n      <td>44.2937</td>\n      <td>56.6338</td>\n      <td>58.9984</td>\n      <td>59</td>\n      <td>29.353</td>\n      <td>17.4241</td>\n      <td>303.598</td>\n      <td>0.0142562</td>\n      <td>-1.21531</td>\n    </tr>\n    <tr>\n      <th>dropoff_second</th>\n      <td>FieldType.DECIMAL</td>\n      <td>0</td>\n      <td>59</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5.03373</td>\n      <td>5</td>\n      <td>14.7471</td>\n      <td>29.598</td>\n      <td>45.3216</td>\n      <td>56.1044</td>\n      <td>58.9728</td>\n      <td>59</td>\n      <td>29.7923</td>\n      <td>17.481</td>\n      <td>305.585</td>\n      <td>-0.0281313</td>\n      <td>-1.21965</td>\n    </tr>\n    <tr>\n      <th>store_forward</th>\n      <td>FieldType.STRING</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>pickup_longitude</th>\n      <td>FieldType.DECIMAL</td>\n      <td>-74.0782</td>\n      <td>-73.7365</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-74.0763</td>\n      <td>-73.9625</td>\n      <td>-73.9629</td>\n      <td>-73.949</td>\n      <td>-73.9279</td>\n      <td>-73.8667</td>\n      <td>-73.8304</td>\n      <td>-73.8232</td>\n      <td>-73.7698</td>\n      <td>-73.9139</td>\n      <td>0.0487111</td>\n      <td>0.00237277</td>\n      <td>0.402697</td>\n      <td>-0.613516</td>\n    </tr>\n    <tr>\n      <th>pickup_latitude</th>\n      <td>FieldType.DECIMAL</td>\n      <td>40.5755</td>\n      <td>40.8799</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.6329</td>\n      <td>40.7131</td>\n      <td>40.7116</td>\n      <td>40.7214</td>\n      <td>40.7581</td>\n      <td>40.8051</td>\n      <td>40.8489</td>\n      <td>40.8676</td>\n      <td>40.8777</td>\n      <td>40.7652</td>\n      <td>0.0483485</td>\n      <td>0.00233758</td>\n      <td>0.228088</td>\n      <td>-0.598862</td>\n    </tr>\n    <tr>\n      <th>dropoff_longitude</th>\n      <td>FieldType.DECIMAL</td>\n      <td>-74.0857</td>\n      <td>-73.7209</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-74.0788</td>\n      <td>-73.9856</td>\n      <td>-73.9858</td>\n      <td>-73.959</td>\n      <td>-73.9367</td>\n      <td>-73.8848</td>\n      <td>-73.8155</td>\n      <td>-73.7767</td>\n      <td>-73.7335</td>\n      <td>-73.9207</td>\n      <td>0.055961</td>\n      <td>0.00313163</td>\n      <td>0.648649</td>\n      <td>0.0229141</td>\n    </tr>\n    <tr>\n      <th>dropoff_latitude</th>\n      <td>FieldType.DECIMAL</td>\n      <td>40.5835</td>\n      <td>40.8797</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.5977</td>\n      <td>40.6954</td>\n      <td>40.6951</td>\n      <td>40.7275</td>\n      <td>40.7582</td>\n      <td>40.7884</td>\n      <td>40.8504</td>\n      <td>40.868</td>\n      <td>40.8786</td>\n      <td>40.7595</td>\n      <td>0.0504621</td>\n      <td>0.00254642</td>\n      <td>0.0484179</td>\n      <td>-0.0368799</td>\n    </tr>\n    <tr>\n      <th>passengers</th>\n      <td>FieldType.DECIMAL</td>\n      <td>1</td>\n      <td>6</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2.32979</td>\n      <td>1.79978</td>\n      <td>3.2392</td>\n      <td>0.834099</td>\n      <td>-1.11111</td>\n    </tr>\n    <tr>\n      <th>cost</th>\n      <td>FieldType.DECIMAL</td>\n      <td>0</td>\n      <td>444</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>7059.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3.01808</td>\n      <td>3.0125</td>\n      <td>5.91545</td>\n      <td>9.49055</td>\n      <td>16.5816</td>\n      <td>33.5638</td>\n      <td>51.9924</td>\n      <td>81.1368</td>\n      <td>12.9112</td>\n      <td>11.6447</td>\n      <td>135.599</td>\n      <td>8.6842</td>\n      <td>269.818</td>\n    </tr>\n  </tbody>\n</table>",
            "text/plain": "ColumnProfile\n    name: vendor\n    type: FieldType.STRING\n\n    min: 1\n    max: VTS\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\nColumnProfile\n    name: pickup_weekday\n    type: FieldType.STRING\n\n    min: Friday\n    max: Wednesday\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\nColumnProfile\n    name: pickup_hour\n    type: FieldType.DECIMAL\n\n    min: 0.0\n    max: 23.0\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 0.0\n           1%: 3.5752283522104507\n           5%: 3.0\n          25%: 9.911063829787235\n          50%: 15.932650462962965\n          75%: 19.0\n          95%: 22.02253132832079\n          99%: 23.0\n        99.9%: 23.0\n\n    mean: 14.232610851395394\n    std: 6.3492619547979405\n    variance: 40.313127370644565\n    skewness: -0.6933346236330169\n    kurtosis: -0.45933637654018833 \n\nColumnProfile\n    name: pickup_minute\n    type: FieldType.DECIMAL\n\n    min: 0.0\n    max: 59.0\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 0.0\n           1%: 5.32313238004232\n           5%: 4.923076923076923\n          25%: 14.22138158887246\n          50%: 29.524351150387936\n          75%: 44.643550881534175\n          95%: 56.37669894736841\n          99%: 58.97980158730159\n        99.9%: 59.0\n\n    mean: 29.463521745289782\n    std: 17.43961511160089\n    variance: 304.1401752407781\n    skewness: 0.004403235186436642\n    kurtosis: -1.2045825872291442 \n\nColumnProfile\n    name: pickup_second\n    type: FieldType.DECIMAL\n\n    min: 0.0\n    max: 59.0\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 0.0\n           1%: 4.992863568215893\n           5%: 4.919540229885057\n          25%: 14.612145838603592\n          50%: 29.923913056037986\n          75%: 44.52206918340458\n          95%: 56.67923258774323\n          99%: 59.0\n        99.9%: 59.0\n\n    mean: 29.62246777163907\n    std: 17.386831494248195\n    variance: 302.30190940938087\n    skewness: -0.022746584878602084\n    kurtosis: -1.194086022369568 \n\nColumnProfile\n    name: dropoff_weekday\n    type: FieldType.STRING\n\n    min: Friday\n    max: Wednesday\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\nColumnProfile\n    name: dropoff_hour\n    type: FieldType.DECIMAL\n\n    min: 0.0\n    max: 23.0\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 0.0\n           1%: 3.232172208560535\n           5%: 2.933333333333334\n          25%: 9.923335054207538\n          50%: 15.913497390007455\n          75%: 19.0\n          95%: 22.2738821600947\n          99%: 23.0\n        99.9%: 23.0\n\n    mean: 14.181470463238407\n    std: 6.455775577121015\n    variance: 41.67703830215217\n    skewness: -0.6910013185430696\n    kurtosis: -0.5002151925128597 \n\nColumnProfile\n    name: dropoff_minute\n    type: FieldType.DECIMAL\n\n    min: 0.0\n    max: 59.0\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 0.0\n           1%: 5.106397306397308\n           5%: 5.0\n          25%: 14.205104167893442\n          50%: 29.078992484013884\n          75%: 44.29369134145639\n          95%: 56.633802040253634\n          99%: 58.99841716968478\n        99.9%: 59.0\n\n    mean: 29.353024507720626\n    std: 17.424053976460392\n    variance: 303.59765697460523\n    skewness: 0.014256204213822449\n    kurtosis: -1.2153056342997897 \n\nColumnProfile\n    name: dropoff_second\n    type: FieldType.DECIMAL\n\n    min: 0.0\n    max: 59.0\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 0.0\n           1%: 5.033732868052396\n           5%: 5.0\n          25%: 14.747134909031837\n          50%: 29.597996746090672\n          75%: 45.321600541894085\n          95%: 56.1043978748524\n          99%: 58.97276759884281\n        99.9%: 59.0\n\n    mean: 29.79232185862021\n    std: 17.481000267086447\n    variance: 305.58537033787644\n    skewness: -0.028131321936678208\n    kurtosis: -1.2196460943795095 \n\nColumnProfile\n    name: store_forward\n    type: FieldType.STRING\n\n    min: N\n    max: Y\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\nColumnProfile\n    name: pickup_longitude\n    type: FieldType.DECIMAL\n\n    min: -74.07815551757812\n    max: -73.73648071289062\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: -74.07631370966985\n           1%: -73.9625417826972\n           5%: -73.96289280187659\n          25%: -73.94897526011049\n          50%: -73.92785596940737\n          75%: -73.86666217823169\n          95%: -73.83043796475843\n          99%: -73.82315963407392\n        99.9%: -73.7697500491672\n\n    mean: -73.91386493958264\n    std: 0.04871109408945094\n    variance: 0.002372770687391343\n    skewness: 0.40269738982876896\n    kurtosis: -0.6135155980288367 \n\nColumnProfile\n    name: pickup_latitude\n    type: FieldType.DECIMAL\n\n    min: 40.57548522949219\n    max: 40.879852294921875\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 40.63288361049421\n           1%: 40.71310498754009\n           5%: 40.711600486268395\n          25%: 40.72140272221352\n          50%: 40.75814186452434\n          75%: 40.805145385926856\n          95%: 40.848855107287775\n          99%: 40.86756701007114\n        99.9%: 40.87769007730938\n\n    mean: 40.76522599299848\n    std: 0.048348486975952946\n    variance: 0.002337576192863892\n    skewness: 0.22808816936950824\n    kurtosis: -0.5988623711401839 \n\nColumnProfile\n    name: dropoff_longitude\n    type: FieldType.DECIMAL\n\n    min: -74.08574676513672\n    max: -73.72087097167969\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: -74.07882847417197\n           1%: -73.9856499467987\n           5%: -73.98581267588766\n          25%: -73.95904087560866\n          50%: -73.93668113941756\n          75%: -73.88484552601459\n          95%: -73.815507217908\n          99%: -73.77669676636948\n        99.9%: -73.73347148887557\n\n    mean: -73.92071783817232\n    std: 0.05596095716658376\n    variance: 0.003131628727000222\n    skewness: 0.648648946871952\n    kurtosis: 0.022914068468275595 \n\nColumnProfile\n    name: dropoff_latitude\n    type: FieldType.DECIMAL\n\n    min: 40.58353042602539\n    max: 40.87973403930664\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 40.59774122979339\n           1%: 40.69537609148018\n           5%: 40.695114665492476\n          25%: 40.72754927370802\n          50%: 40.758160378291606\n          75%: 40.788378073909165\n          95%: 40.85037214749771\n          99%: 40.867968246603375\n        99.9%: 40.878585531071245\n\n    mean: 40.7594872258256\n    std: 0.05046209380939558\n    variance: 0.0025464229116282395\n    skewness: 0.048417933848660985\n    kurtosis: -0.0368799343056212 \n\nColumnProfile\n    name: passengers\n    type: FieldType.DECIMAL\n\n    min: 1.0\n    max: 6.0\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 1.0\n           1%: 1.0\n           5%: 1.0\n          25%: 1.0\n          50%: 1.0\n          75%: 5.0\n          95%: 5.0\n          99%: 6.0\n        99.9%: 6.0\n\n    mean: 2.3297917552061156\n    std: 1.7997766302118896\n    variance: 3.239195918656865\n    skewness: 0.8340985645144754\n    kurtosis: -1.1111097095315299 \n\nColumnProfile\n    name: cost\n    type: FieldType.DECIMAL\n\n    min: 0.0\n    max: 444.0\n    count: 7059.0\n    missing_count: 0.0\n    not_missing_count: 7059.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 0.0\n           1%: 3.0180822649572656\n           5%: 3.0125\n          25%: 5.915451150004527\n          50%: 9.490553841275261\n          75%: 16.581562244062244\n          95%: 33.56382066951073\n          99%: 51.992409200968524\n        99.9%: 81.13681176470527\n\n    mean: 12.911225386032\n    std: 11.64471948001604\n    variance: 135.599491768265\n    skewness: 8.684200777604197\n    kurtosis: 269.81754443324434 "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You prepare the data for the experiment by adding columns to `dflow_X` to be features for our model creation. You define `dflow_y` to be our prediction value; cost.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dflow_X = dflow_prepared.keep_columns(['pickup_weekday', 'dropoff_latitude', 'dropoff_longitude','pickup_hour','pickup_longitude','pickup_latitude','passengers'])\ndflow_y = dflow_prepared.keep_columns('cost')",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Split data into train and test sets\n\nNow you split the data into training and test sets using the `train_test_split` function in the `sklearn` library. This function segregates the data into the x (features) data set for model training and the y (values to predict) data set for testing. The `test_size` parameter determines the percentage of data to allocate to testing. The `random_state` parameter sets a seed to the random generator, so that your train-test splits are always deterministic."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\n\nx_df = dflow_X.to_pandas_dataframe()\ny_df = dflow_y.to_pandas_dataframe()\n\nx_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=123)\n# flatten y_train to 1d array\ny_train.values.flatten()",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "array([19. ,  8.5, 15.5, ...,  6. ,  7. ,  2.5])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You now have the necessary packages and data ready for auto training for your model. \n\n## Automatically train a model\n\nTo automatically train a model:\n1. Define settings for the experiment run\n1. Submit the experiment for model tuning\n\n\n### Define settings for autogeneration and tuning\n\nDefine the experiment parameters and models settings for autogeneration and tuning. View the full list of [settings](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train).\n\n\n|Property| Value in this tutorial |Description|\n|----|----|---|\n|**iteration_timeout_minutes**|10|Time limit in minutes for each iteration|\n|**iterations**|30|Number of iterations. In each iteration, the model trains with the data with a specific pipeline|\n|**primary_metric**|spearman_correlation | Metric that you want to optimize.|\n|**preprocess**| True | True enables experiment to perform preprocessing on the input.|\n|**verbosity**| logging.INFO | Controls the level of logging.|\n|**n_cross_validationss**|5|Number of cross validation splits\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_settings = {\n    \"iteration_timeout_minutes\" : 10,\n    \"iterations\" : 30,\n    \"primary_metric\" : 'spearman_correlation',\n    \"preprocess\" : True,\n    \"verbosity\" : logging.INFO,\n    \"n_cross_validations\": 5\n}",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "tags": [
          "configure automl"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.automl import AutoMLConfig\n\n# local compute \nautomated_ml_config = AutoMLConfig(task = 'regression',\n                             debug_log = 'automated_ml_errors.log',\n                             path = project_folder,\n                             X = x_train.values,\n                             y = y_train.values.flatten(),\n                             **automl_settings)",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Train the automatic regression model\n\nStart the experiment to run locally. Pass the defined `automated_ml_config` object to the experiment, and set the output to `true` to view progress during the experiment."
    },
    {
      "metadata": {
        "tags": [
          "local submitted run",
          "automl"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.experiment import Experiment\nexperiment=Experiment(ws, experiment_name)\nlocal_run = experiment.submit(automated_ml_config, show_output=True)",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Parent Run ID: AutoML_f715298d-5733-4fa5-bbe8-c2c3145f22f1\n*******************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n*******************************************************************************************\n\n ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n         0   MaxAbsScaler ExtremeRandomTrees                0:01:02       0.5362    0.5362\n         1   MaxAbsScaler GradientBoosting                  0:02:07       0.4250    0.5362\n         2   MaxAbsScaler ExtremeRandomTrees                0:00:49       0.6356    0.6356\n         3   MaxAbsScaler GradientBoosting                  0:00:55       0.7245    0.7245\n         4   StandardScalerWrapper GradientBoosting         0:03:17       0.7211    0.7245\n         5   SparseNormalizer RandomForest                  0:01:29       0.7790    0.7790\n         6   StandardScalerWrapper GradientBoosting         0:00:48       0.7463    0.7790\n         7   MaxAbsScaler GradientBoosting                  0:01:33       0.7882    0.7882\n         8   StandardScalerWrapper RandomForest             0:00:45       0.7168    0.7882\n         9   MaxAbsScaler LightGBM                          0:00:37       0.5972    0.7882\n        10   ",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "MSI: Failed to retrieve a token from 'http://localhost:25198/nb/api/nbsvc/oauth2/token' with an error of 'HTTPConnectionPool(host='localhost', port=25198): Max retries exceeded with url: /nb/api/nbsvc/oauth2/token (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f175f9ab1d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))'. This could be caused by the MSI extension not yet fullly provisioned.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "MaxAbsScaler LightGBM                          0:00:47       0.7500    0.7882\n        11   StandardScalerWrapper LightGBM                 0:00:37       0.7165    0.7882\n        12   SparseNormalizer ExtremeRandomTrees            0:01:34       0.3050    0.7882\n        13   MaxAbsScaler DecisionTree                      0:00:53       0.6566    0.7882\n        14   MaxAbsScaler RandomForest                      0:00:47       0.6604    0.7882\n        15   MaxAbsScaler ExtremeRandomTrees                0:00:47       0.6192    0.7882\n        16   MaxAbsScaler RandomForest                      0:05:14       0.8129    0.8129\n        17   MaxAbsScaler RandomForest                      0:01:06       0.6599    0.8129\n        18   StandardScalerWrapper ExtremeRandomTrees       0:00:47       0.3586    0.8129\n        19   MaxAbsScaler RandomForest                      0:00:48       0.4758    0.8129\n        20   StandardScalerWrapper LightGBM                 0:00:56       0.6883    0.8129\n        21   MaxAbsScaler DecisionTree                      0:00:47       0.6355    0.8129\n        22   MaxAbsScaler DecisionTree                      0:00:41       0.6195    0.8129\n        23   MaxAbsScaler DecisionTree                      0:00:49       0.6945    0.8129\n        24   StandardScalerWrapper LightGBM                 0:01:08       0.7615    0.8129\n        25   ",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "MSI: Failed to retrieve a token from 'http://localhost:25198/nb/api/nbsvc/oauth2/token' with an error of 'HTTPConnectionPool(host='localhost', port=25198): Max retries exceeded with url: /nb/api/nbsvc/oauth2/token (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f175dd2d128>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))'. This could be caused by the MSI extension not yet fullly provisioned.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "MaxAbsScaler SGD                               0:00:48       0.0452    0.8129\n        26   ",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "MSI: Failed to retrieve a token from 'http://localhost:25198/nb/api/nbsvc/oauth2/token' with an error of 'HTTPConnectionPool(host='localhost', port=25198): Max retries exceeded with url: /nb/api/nbsvc/oauth2/token (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f175dcfa828>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))'. This could be caused by the MSI extension not yet fullly provisioned.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "StandardScalerWrapper DecisionTree             0:00:51       0.6750    0.8129\n        27   StandardScalerWrapper ExtremeRandomTrees       0:01:05       0.6634    0.8129\n        28   MaxAbsScaler DecisionTree                      0:00:51       0.6479    0.8129\n        29    Ensemble                                      0:04:14       0.8427    0.8427\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Explore the results\n\nExplore the results of automatic training with a Jupyter widget or by examining the experiment history.\n\n### Option 1: Add a Jupyter widget to see results\n\nUse the Jupyter notebook widget to see a graph and a table of all results."
    },
    {
      "metadata": {
        "tags": [
          "use notebook widget"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(local_run).show()",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17324d7cc09847b78370f34f4644842f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sd…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Option 2: Get and examine all run iterations in Python\n\nAlternatively, you can retrieve the history of each experiment and explore the individual metrics for each iteration run."
    },
    {
      "metadata": {
        "tags": [
          "get metrics",
          "query history"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "children = list(local_run.get_children())\nmetricslist = {}\nfor run in children:\n    properties = run.get_properties()\n    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n    metricslist[int(properties['iteration'])] = metrics\n\nimport pandas as pd\nrundata = pd.DataFrame(metricslist).sort_index(1)\nrundata",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>explained_variance</th>\n      <td>0.127213</td>\n      <td>0.122456</td>\n      <td>0.224217</td>\n      <td>0.382238</td>\n      <td>0.353439</td>\n      <td>0.443718</td>\n      <td>0.457082</td>\n      <td>0.498826</td>\n      <td>0.381608</td>\n      <td>0.284133</td>\n      <td>...</td>\n      <td>0.357091</td>\n      <td>0.331669</td>\n      <td>0.339121</td>\n      <td>0.382699</td>\n      <td>0.458525</td>\n      <td>-0.001764</td>\n      <td>0.375429</td>\n      <td>0.249744</td>\n      <td>0.334401</td>\n      <td>0.494338</td>\n    </tr>\n    <tr>\n      <th>mean_absolute_error</th>\n      <td>6.394824</td>\n      <td>6.409890</td>\n      <td>6.327570</td>\n      <td>4.857654</td>\n      <td>4.785398</td>\n      <td>4.339912</td>\n      <td>4.278462</td>\n      <td>3.627265</td>\n      <td>5.033176</td>\n      <td>5.985938</td>\n      <td>...</td>\n      <td>4.617597</td>\n      <td>5.300992</td>\n      <td>5.127000</td>\n      <td>4.626284</td>\n      <td>3.772906</td>\n      <td>7.728627</td>\n      <td>4.708356</td>\n      <td>6.128216</td>\n      <td>5.265543</td>\n      <td>3.454024</td>\n    </tr>\n    <tr>\n      <th>median_absolute_error</th>\n      <td>3.873000</td>\n      <td>3.889245</td>\n      <td>5.101538</td>\n      <td>3.347935</td>\n      <td>3.032882</td>\n      <td>2.869871</td>\n      <td>2.964672</td>\n      <td>2.164105</td>\n      <td>3.609615</td>\n      <td>4.862259</td>\n      <td>...</td>\n      <td>2.748236</td>\n      <td>3.570471</td>\n      <td>3.404129</td>\n      <td>2.805219</td>\n      <td>2.060650</td>\n      <td>6.329966</td>\n      <td>2.887346</td>\n      <td>4.886083</td>\n      <td>3.532190</td>\n      <td>1.981099</td>\n    </tr>\n    <tr>\n      <th>normalized_mean_absolute_error</th>\n      <td>0.014403</td>\n      <td>0.014437</td>\n      <td>0.014251</td>\n      <td>0.010941</td>\n      <td>0.010778</td>\n      <td>0.009775</td>\n      <td>0.009636</td>\n      <td>0.008170</td>\n      <td>0.011336</td>\n      <td>0.013482</td>\n      <td>...</td>\n      <td>0.010400</td>\n      <td>0.011939</td>\n      <td>0.011547</td>\n      <td>0.010420</td>\n      <td>0.008498</td>\n      <td>0.017407</td>\n      <td>0.010604</td>\n      <td>0.013802</td>\n      <td>0.011859</td>\n      <td>0.007779</td>\n    </tr>\n    <tr>\n      <th>normalized_median_absolute_error</th>\n      <td>0.008723</td>\n      <td>0.008760</td>\n      <td>0.011490</td>\n      <td>0.007540</td>\n      <td>0.006831</td>\n      <td>0.006464</td>\n      <td>0.006677</td>\n      <td>0.004874</td>\n      <td>0.008130</td>\n      <td>0.010951</td>\n      <td>...</td>\n      <td>0.006190</td>\n      <td>0.008042</td>\n      <td>0.007667</td>\n      <td>0.006318</td>\n      <td>0.004641</td>\n      <td>0.014257</td>\n      <td>0.006503</td>\n      <td>0.011005</td>\n      <td>0.007955</td>\n      <td>0.004462</td>\n    </tr>\n    <tr>\n      <th>normalized_root_mean_squared_error</th>\n      <td>0.025779</td>\n      <td>0.025799</td>\n      <td>0.023534</td>\n      <td>0.021142</td>\n      <td>0.021757</td>\n      <td>0.020104</td>\n      <td>0.019877</td>\n      <td>0.019107</td>\n      <td>0.021145</td>\n      <td>0.022668</td>\n      <td>...</td>\n      <td>0.021496</td>\n      <td>0.021949</td>\n      <td>0.021810</td>\n      <td>0.021108</td>\n      <td>0.019829</td>\n      <td>0.026569</td>\n      <td>0.021250</td>\n      <td>0.023177</td>\n      <td>0.021898</td>\n      <td>0.019261</td>\n    </tr>\n    <tr>\n      <th>normalized_root_mean_squared_log_error</th>\n      <td>0.099605</td>\n      <td>0.102303</td>\n      <td>0.103526</td>\n      <td>0.085103</td>\n      <td>0.081573</td>\n      <td>0.080072</td>\n      <td>0.081296</td>\n      <td>0.074454</td>\n      <td>0.087789</td>\n      <td>0.101485</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.090011</td>\n      <td>0.090018</td>\n      <td>0.084086</td>\n      <td>NaN</td>\n      <td>0.119977</td>\n      <td>0.085795</td>\n      <td>0.100877</td>\n      <td>0.089165</td>\n      <td>0.069029</td>\n    </tr>\n    <tr>\n      <th>r2_score</th>\n      <td>0.060549</td>\n      <td>0.059197</td>\n      <td>0.224001</td>\n      <td>0.381609</td>\n      <td>0.343740</td>\n      <td>0.442939</td>\n      <td>0.456488</td>\n      <td>0.498310</td>\n      <td>0.381235</td>\n      <td>0.283822</td>\n      <td>...</td>\n      <td>0.355213</td>\n      <td>0.331216</td>\n      <td>0.338542</td>\n      <td>0.382110</td>\n      <td>0.457332</td>\n      <td>-0.002994</td>\n      <td>0.374659</td>\n      <td>0.249453</td>\n      <td>0.334126</td>\n      <td>0.490206</td>\n    </tr>\n    <tr>\n      <th>root_mean_squared_error</th>\n      <td>11.445961</td>\n      <td>11.454774</td>\n      <td>10.449223</td>\n      <td>9.386954</td>\n      <td>9.660134</td>\n      <td>8.926020</td>\n      <td>8.825459</td>\n      <td>8.483502</td>\n      <td>9.388254</td>\n      <td>10.064670</td>\n      <td>...</td>\n      <td>9.544199</td>\n      <td>9.745504</td>\n      <td>9.683633</td>\n      <td>9.371840</td>\n      <td>8.804037</td>\n      <td>11.796664</td>\n      <td>9.434914</td>\n      <td>10.290641</td>\n      <td>9.722506</td>\n      <td>8.551961</td>\n    </tr>\n    <tr>\n      <th>root_mean_squared_log_error</th>\n      <td>0.607398</td>\n      <td>0.623854</td>\n      <td>0.631307</td>\n      <td>0.518962</td>\n      <td>0.497438</td>\n      <td>0.488283</td>\n      <td>0.495747</td>\n      <td>0.454024</td>\n      <td>0.535346</td>\n      <td>0.618863</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.548893</td>\n      <td>0.548937</td>\n      <td>0.512762</td>\n      <td>NaN</td>\n      <td>0.731631</td>\n      <td>0.523185</td>\n      <td>0.615155</td>\n      <td>0.543736</td>\n      <td>0.420947</td>\n    </tr>\n    <tr>\n      <th>spearman_correlation</th>\n      <td>0.536197</td>\n      <td>0.425013</td>\n      <td>0.635561</td>\n      <td>0.724526</td>\n      <td>0.721145</td>\n      <td>0.778988</td>\n      <td>0.746328</td>\n      <td>0.788225</td>\n      <td>0.716796</td>\n      <td>0.597244</td>\n      <td>...</td>\n      <td>0.688267</td>\n      <td>0.635529</td>\n      <td>0.619478</td>\n      <td>0.694514</td>\n      <td>0.761520</td>\n      <td>0.045212</td>\n      <td>0.674991</td>\n      <td>0.663438</td>\n      <td>0.647902</td>\n      <td>0.842691</td>\n    </tr>\n    <tr>\n      <th>spearman_correlation_max</th>\n      <td>0.536197</td>\n      <td>0.536197</td>\n      <td>0.635561</td>\n      <td>0.724526</td>\n      <td>0.724526</td>\n      <td>0.778988</td>\n      <td>0.778988</td>\n      <td>0.788225</td>\n      <td>0.788225</td>\n      <td>0.788225</td>\n      <td>...</td>\n      <td>0.812874</td>\n      <td>0.812874</td>\n      <td>0.812874</td>\n      <td>0.812874</td>\n      <td>0.812874</td>\n      <td>0.812874</td>\n      <td>0.812874</td>\n      <td>0.812874</td>\n      <td>0.812874</td>\n      <td>0.842691</td>\n    </tr>\n  </tbody>\n</table>\n<p>12 rows × 30 columns</p>\n</div>",
            "text/plain": "                                                0          1          2  \\\nexplained_variance                      0.127213   0.122456   0.224217    \nmean_absolute_error                     6.394824   6.409890   6.327570    \nmedian_absolute_error                   3.873000   3.889245   5.101538    \nnormalized_mean_absolute_error          0.014403   0.014437   0.014251    \nnormalized_median_absolute_error        0.008723   0.008760   0.011490    \nnormalized_root_mean_squared_error      0.025779   0.025799   0.023534    \nnormalized_root_mean_squared_log_error  0.099605   0.102303   0.103526    \nr2_score                                0.060549   0.059197   0.224001    \nroot_mean_squared_error                 11.445961  11.454774  10.449223   \nroot_mean_squared_log_error             0.607398   0.623854   0.631307    \nspearman_correlation                    0.536197   0.425013   0.635561    \nspearman_correlation_max                0.536197   0.536197   0.635561    \n\n                                               3         4         5  \\\nexplained_variance                      0.382238  0.353439  0.443718   \nmean_absolute_error                     4.857654  4.785398  4.339912   \nmedian_absolute_error                   3.347935  3.032882  2.869871   \nnormalized_mean_absolute_error          0.010941  0.010778  0.009775   \nnormalized_median_absolute_error        0.007540  0.006831  0.006464   \nnormalized_root_mean_squared_error      0.021142  0.021757  0.020104   \nnormalized_root_mean_squared_log_error  0.085103  0.081573  0.080072   \nr2_score                                0.381609  0.343740  0.442939   \nroot_mean_squared_error                 9.386954  9.660134  8.926020   \nroot_mean_squared_log_error             0.518962  0.497438  0.488283   \nspearman_correlation                    0.724526  0.721145  0.778988   \nspearman_correlation_max                0.724526  0.724526  0.778988   \n\n                                               6         7         8  \\\nexplained_variance                      0.457082  0.498826  0.381608   \nmean_absolute_error                     4.278462  3.627265  5.033176   \nmedian_absolute_error                   2.964672  2.164105  3.609615   \nnormalized_mean_absolute_error          0.009636  0.008170  0.011336   \nnormalized_median_absolute_error        0.006677  0.004874  0.008130   \nnormalized_root_mean_squared_error      0.019877  0.019107  0.021145   \nnormalized_root_mean_squared_log_error  0.081296  0.074454  0.087789   \nr2_score                                0.456488  0.498310  0.381235   \nroot_mean_squared_error                 8.825459  8.483502  9.388254   \nroot_mean_squared_log_error             0.495747  0.454024  0.535346   \nspearman_correlation                    0.746328  0.788225  0.716796   \nspearman_correlation_max                0.778988  0.788225  0.788225   \n\n                                                9    ...           20  \\\nexplained_variance                      0.284133     ...     0.357091   \nmean_absolute_error                     5.985938     ...     4.617597   \nmedian_absolute_error                   4.862259     ...     2.748236   \nnormalized_mean_absolute_error          0.013482     ...     0.010400   \nnormalized_median_absolute_error        0.010951     ...     0.006190   \nnormalized_root_mean_squared_error      0.022668     ...     0.021496   \nnormalized_root_mean_squared_log_error  0.101485     ...    NaN         \nr2_score                                0.283822     ...     0.355213   \nroot_mean_squared_error                 10.064670    ...     9.544199   \nroot_mean_squared_log_error             0.618863     ...    NaN         \nspearman_correlation                    0.597244     ...     0.688267   \nspearman_correlation_max                0.788225     ...     0.812874   \n\n                                              21        22        23  \\\nexplained_variance                      0.331669  0.339121  0.382699   \nmean_absolute_error                     5.300992  5.127000  4.626284   \nmedian_absolute_error                   3.570471  3.404129  2.805219   \nnormalized_mean_absolute_error          0.011939  0.011547  0.010420   \nnormalized_median_absolute_error        0.008042  0.007667  0.006318   \nnormalized_root_mean_squared_error      0.021949  0.021810  0.021108   \nnormalized_root_mean_squared_log_error  0.090011  0.090018  0.084086   \nr2_score                                0.331216  0.338542  0.382110   \nroot_mean_squared_error                 9.745504  9.683633  9.371840   \nroot_mean_squared_log_error             0.548893  0.548937  0.512762   \nspearman_correlation                    0.635529  0.619478  0.694514   \nspearman_correlation_max                0.812874  0.812874  0.812874   \n\n                                              24         25        26  \\\nexplained_variance                      0.458525 -0.001764   0.375429   \nmean_absolute_error                     3.772906  7.728627   4.708356   \nmedian_absolute_error                   2.060650  6.329966   2.887346   \nnormalized_mean_absolute_error          0.008498  0.017407   0.010604   \nnormalized_median_absolute_error        0.004641  0.014257   0.006503   \nnormalized_root_mean_squared_error      0.019829  0.026569   0.021250   \nnormalized_root_mean_squared_log_error NaN        0.119977   0.085795   \nr2_score                                0.457332 -0.002994   0.374659   \nroot_mean_squared_error                 8.804037  11.796664  9.434914   \nroot_mean_squared_log_error            NaN        0.731631   0.523185   \nspearman_correlation                    0.761520  0.045212   0.674991   \nspearman_correlation_max                0.812874  0.812874   0.812874   \n\n                                               27        28        29  \nexplained_variance                      0.249744   0.334401  0.494338  \nmean_absolute_error                     6.128216   5.265543  3.454024  \nmedian_absolute_error                   4.886083   3.532190  1.981099  \nnormalized_mean_absolute_error          0.013802   0.011859  0.007779  \nnormalized_median_absolute_error        0.011005   0.007955  0.004462  \nnormalized_root_mean_squared_error      0.023177   0.021898  0.019261  \nnormalized_root_mean_squared_log_error  0.100877   0.089165  0.069029  \nr2_score                                0.249453   0.334126  0.490206  \nroot_mean_squared_error                 10.290641  9.722506  8.551961  \nroot_mean_squared_log_error             0.615155   0.543736  0.420947  \nspearman_correlation                    0.663438   0.647902  0.842691  \nspearman_correlation_max                0.812874   0.812874  0.842691  \n\n[12 rows x 30 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Retrieve the best model\n\nSelect the best pipeline from our iterations. The `get_output` method on `automl_classifier` returns the best run and the fitted model for the last fit invocation. There are overloads on `get_output` that allow you to retrieve the best run and fitted model for any logged metric or a particular iteration."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = local_run.get_output()\nprint(best_run)\nprint(fitted_model)",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: automated-ml-regression,\nId: AutoML_f715298d-5733-4fa5-bbe8-c2c3145f22f1_29,\nType: None,\nStatus: Completed)\nPipeline(memory=None,\n     steps=[('datatransformer', DataTransformer(logger=None, task=None)), ('prefittedsoftvotingregressor', PreFittedSoftVotingRegressor(estimators=[('RandomForest', Pipeline(memory=None,\n     steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=False...nsform=None,\n               weights=[0.5333333333333333, 0.13333333333333333, 0.3333333333333333]))])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Register the model\n\nRegister the model in your Azure Machine Learning Workspace."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "description = 'Automated Machine Learning Model'\ntags = None\nlocal_run.register_model(description=description, tags=tags)\nlocal_run.model_id # Use this id to deploy the model as a web service in Azure",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Registering model AutoMLf715298d5best\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "'AutoMLf715298d5best'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test the best model accuracy\n\nUse the best model to run predictions on the test data set. The function `predict` uses the best model, and predicts the values of y (trip cost) from the `x_test` data set. Print the first 10 predicted cost values from `y_predict`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_predict = fitted_model.predict(x_test.values) \nprint(y_predict[:10])",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[ 8.38708077  8.8706504   8.70706933  8.64981801  6.80996859  7.43748343\n  7.72175158 28.72376002  7.57333283 23.1779971 ]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Compare the predicted cost values with the actual cost values. Use the `y_test` dataframe, and convert it to a list to compare to the predicted values. The function `mean_absolute_error` takes two arrays of values, and calculates the average absolute value error between them. In this example, a mean absolute error of 3.5 would mean that on average, the model predicts the cost within plus or minus 3.5 of the actual value."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_absolute_error\n\ny_actual = y_test.values.flatten().tolist()\nprint(\"Mean Absolute Error :\")\nmean_absolute_error(y_actual, y_predict)",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Mean Absolute Error :\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "3.1235324986518913"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Run the following code to calculate MAPE (mean absolute percent error) using the full `y_actual` and `y_predict` data sets. This metric calculates an absolute difference between each predicted and actual value, sums all the differences, and then expresses that sum as a percent of the total of the actual values."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sum_actuals = sum_errors = 0\n\nfor actual_val, predict_val in zip(y_actual, y_predict):\n    abs_error = actual_val - predict_val\n    if abs_error < 0:\n        abs_error = abs_error * -1\n    \n    sum_errors = sum_errors + abs_error\n    sum_actuals = sum_actuals + actual_val\n    \nmean_abs_percent_error = sum_errors / sum_actuals\nprint(\"Model MAPE :\")\nprint(mean_abs_percent_error)\nprint()\nprint(\"Model Accuracy :\")\nprint(1 - mean_abs_percent_error)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Model MAPE :\n0.24793424410420511\n\nModel Accuracy :\n0.7520657558957948\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "jeffshep"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "msauthor": "sgilley"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}